{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f268f26-a03e-4817-a715-188f7d2927f4",
   "metadata": {},
   "source": [
    "This model Generate the Answer & Not stored the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1097c6a4-8ebc-4d53-b878-885c919582ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the QA system!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a word to search information about (or type 'exit' to end):  exit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from docx import Document\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "OpenAI.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI()\n",
    "\n",
    "def read_qa_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    qa_dict = {}\n",
    "\n",
    "    current_question = None\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text = paragraph.text.strip()\n",
    "\n",
    "        if text.endswith(\"?\"):\n",
    "            current_question = text\n",
    "        elif current_question and text.endswith(\".\"):\n",
    "            qa_dict[current_question] = text\n",
    "            current_question = None\n",
    "\n",
    "    return qa_dict\n",
    "\n",
    "def find_matching_question(user_question, questions):\n",
    "    # Use fuzzy string matching to find the closest matching question\n",
    "    matching_question = max(questions, key=lambda question: fuzz.partial_ratio(user_question, question))\n",
    "    return matching_question\n",
    "\n",
    "def search_word_information(user_input):\n",
    "    # Check if the user input matches any question in QA.docx\n",
    "    qa_dict = read_qa_from_docx('QA.docx')\n",
    "    questions = list(qa_dict.keys())\n",
    "\n",
    "    matching_question = find_matching_question(user_input, questions)\n",
    "\n",
    "    if fuzz.partial_ratio(user_input, matching_question) > 60:\n",
    "        print(\"Answer from QA System:\", qa_dict[matching_question])\n",
    "    else:\n",
    "        # If no match is found, use GPT-3.5 Turbo to generate a response\n",
    "        prompt = f\"Search Information about {user_input}\"\n",
    "\n",
    "        response = client.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=150,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        generated_text = response.choices[0].text\n",
    "        print(\"Generated Information:\", generated_text)\n",
    "\n",
    "        print(\"I'm here to offer general information and assist you with related topics. However, I can still provide some more information. Feel free to ask another query!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the QA system!\")\n",
    "    while True:\n",
    "        user_input = input(\"Enter a word to search information about (or type 'exit' to end): \").strip().lower()\n",
    "\n",
    "        if user_input == 'exit':\n",
    "            break\n",
    "\n",
    "        search_word_information(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e15e56-a92f-4042-80bf-f0a3c4b53854",
   "metadata": {},
   "source": [
    "This Model stored the date & generate the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8322cb-aae4-4f40-af43-881ddbcb7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Welcome to the Chat Box that saved the data\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter to search information about (or type 'exit' to end):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Thank You\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from docx import Document\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "OpenAI.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI()\n",
    "\n",
    "def read_qa_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    qa_dict = {}\n",
    "\n",
    "    current_question = None\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text = paragraph.text.strip()\n",
    "\n",
    "        if text.endswith(\"?\"):\n",
    "            current_question = text\n",
    "        elif current_question and text.endswith(\".\"):\n",
    "            qa_dict[current_question] = text\n",
    "            current_question = None\n",
    "\n",
    "    return qa_dict\n",
    "\n",
    "def find_matching_question(user_question, questions):\n",
    "    matching_question = max(questions, key=lambda question: fuzz.partial_ratio(user_question, question))\n",
    "    return matching_question\n",
    "\n",
    "def add_qa_to_docx(docx_path, question, answer):\n",
    "    doc = Document(docx_path)\n",
    "    doc.add_paragraph(question)\n",
    "    doc.add_paragraph(answer)\n",
    "    doc.save(docx_path)\n",
    "\n",
    "def search_word_information(user_input, docx_path='QA.docx'):\n",
    "    qa_dict = read_qa_from_docx(docx_path)\n",
    "    questions = list(qa_dict.keys())\n",
    "\n",
    "    matching_question = find_matching_question(user_input, questions)\n",
    "\n",
    "    if fuzz.partial_ratio(user_input, matching_question) > 60:\n",
    "        print(\"Answer from QA System:\", qa_dict[matching_question])\n",
    "    else:\n",
    "        prompt = f\"Search Information about {user_input}\"\n",
    "\n",
    "        response = client.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        generated_text = response.choices[0].text\n",
    "        print(\"Generated Information:\", generated_text)\n",
    "\n",
    "        # Add the user's question and the generated answer to the document\n",
    "        add_qa_to_docx(docx_path, user_input, generated_text)\n",
    "        print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "        print(\"I'm here to offer general information and assist you with related topics. However, I can still provide some more information. Feel free to ask another query!\")\n",
    "        print('**********************************************************************************************************************************************')\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print(\"Welcome to the Chat Box that saved the data\")\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    while True:\n",
    "        user_input = input(\"Enter to search information about (or type 'exit' to end): \").strip().lower()\n",
    "        print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "        if user_input == 'exit':\n",
    "            print('Thank You')\n",
    "            break\n",
    "        search_word_information(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e434b-d000-4768-98c7-8672a6ffcbd4",
   "metadata": {},
   "source": [
    "This model stored the data in Excel format , CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3574bbed-e4a6-4fca-9634-080018aec13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Welcome to the Chat Bot\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter to search information about (or type 'exit' to end):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Thank You\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "OpenAI.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "client = OpenAI()\n",
    "\n",
    "def read_qa_from_excel(excel_path):\n",
    "    df = pd.read_excel(excel_path)\n",
    "    return df\n",
    "\n",
    "def add_qa_to_excel(excel_path, question, answer):\n",
    "    df = pd.read_excel(excel_path)\n",
    "    new_row = pd.DataFrame({\"Questions\": [question], \"Answers\": [answer]})\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_excel(excel_path, index=False)\n",
    "\n",
    "def find_matching_question(user_question, questions):\n",
    "    if not questions:\n",
    "        return None  # Return None if the list of questions is empty\n",
    "\n",
    "    matching_question = max(questions, key=lambda question: fuzz.partial_ratio(user_question, question))\n",
    "    return matching_question\n",
    "\n",
    "def search_word_information(user_input, excel_path='QA.xlsx'):\n",
    "    qa_df = read_qa_from_excel(excel_path)\n",
    "    questions = list(qa_df[\"Questions\"])\n",
    "\n",
    "    matching_question = find_matching_question(user_input, questions)\n",
    "\n",
    "    if matching_question is not None and fuzz.partial_ratio(user_input, matching_question) > 60:\n",
    "        answer = qa_df.loc[qa_df[\"Questions\"] == matching_question, \"Answers\"].values[0]\n",
    "        print(\"Answer from QA System:\", answer)\n",
    "    else:\n",
    "        prompt = f\"Search Information about {user_input}\"\n",
    "\n",
    "        response = client.completions.create(\n",
    "            model=\"gpt-3.5-turbo-instruct\",\n",
    "            prompt=prompt,\n",
    "            max_tokens=500,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        generated_text = response.choices[0].text\n",
    "        print(\"Generated Information:\", generated_text)\n",
    "\n",
    "        # Add the user's question and the generated answer to the Excel file\n",
    "        add_qa_to_excel(excel_path, user_input, generated_text)\n",
    "        print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "        print(\"I'm here to offer general information and assist you with related topics. However, I can still provide some more information. Feel free to ask another query!\")\n",
    "        print('**********************************************************************************************************************************************')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    print(\"Welcome to the Chat Bot\")\n",
    "    print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    while True:\n",
    "        user_input = input(\"Enter to search information about (or type 'exit' to end): \").strip().lower()\n",
    "        print('----------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "        if user_input == 'exit':\n",
    "            print('Thank You')\n",
    "            break\n",
    "        search_word_information(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e6740-30da-483d-8901-7cad0ecb5adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
